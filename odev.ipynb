{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d33197044d427e949fe20ed69b6d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 10:59:03 INFO: Downloaded file to C:\\Users\\meteb\\stanza_resources\\resources.json\n",
      "2025-05-19 10:59:03 INFO: Downloading default packages for language: tr (Turkish) ...\n",
      "2025-05-19 10:59:03 INFO: File exists: C:\\Users\\meteb\\stanza_resources\\tr\\default.zip\n",
      "2025-05-19 10:59:06 INFO: Finished downloading models and saved to C:\\Users\\meteb\\stanza_resources\n",
      "2025-05-19 10:59:06 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127f535709c84f9794b0d909651fe07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 10:59:06 INFO: Downloaded file to C:\\Users\\meteb\\stanza_resources\\resources.json\n",
      "2025-05-19 10:59:06 INFO: Loading these models for language: tr (Turkish):\n",
      "=============================\n",
      "| Processor | Package       |\n",
      "-----------------------------\n",
      "| tokenize  | imst          |\n",
      "| mwt       | imst          |\n",
      "| pos       | imst_charlm   |\n",
      "| lemma     | imst_nocharlm |\n",
      "| depparse  | imst_charlm   |\n",
      "=============================\n",
      "\n",
      "2025-05-19 10:59:06 INFO: Using device: cpu\n",
      "2025-05-19 10:59:06 INFO: Loading: tokenize\n",
      "2025-05-19 10:59:08 INFO: Loading: mwt\n",
      "2025-05-19 10:59:08 INFO: Loading: pos\n",
      "2025-05-19 10:59:09 INFO: Loading: lemma\n",
      "2025-05-19 10:59:09 INFO: Loading: depparse\n",
      "2025-05-19 10:59:09 INFO: Done loading processors!\n",
      "c:\\Python311\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Python311\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ output.txt başarıyla oluşturuldu ve tüm puanlar kaydedildi!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from puanTRSOV import bul_puanSOV\n",
    "from puanBLEU import bul_puanBLEU\n",
    "from puanBERT import bul_puanBERT\n",
    "\n",
    "# Dosya yolları\n",
    "# referans_dosyasi = \"veriseti_referans.txt\"\n",
    "referans_dosyasi = \"veriseti_test.txt\"\n",
    "test_dosyasi = \"veriseti_LLMcevaplar.txt\"\n",
    "\n",
    "referans_dosyasi = \"veriseti_kck.txt\"\n",
    "test_dosyasi = \"veriseti_LLMkck.txt\"\n",
    "\n",
    "output_dosyasi = \"output.txt\"\n",
    "\n",
    "# Veriyi okuma fonksiyonu\n",
    "def oku_veri(dosya):\n",
    "    veri = []\n",
    "    with open(dosya, \"r\", encoding=\"utf-8\") as file:\n",
    "        reader = csv.reader(file, delimiter=\";\")\n",
    "        next(reader)  # Başlık satırını geç\n",
    "        for row in reader:\n",
    "            veri.append((row[0], row[1]))  # GRUP, CUMLE\n",
    "    return veri\n",
    "\n",
    "# Dosyalardan veriyi al\n",
    "referans_metinleri = oku_veri(referans_dosyasi)\n",
    "test_metinleri = oku_veri(test_dosyasi)\n",
    "\n",
    "# Çıktıyı dosyaya yazma\n",
    "with open(output_dosyasi, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(\"GRUP;SOV_REF;ORDER_REF;SOV_TST;ORDER_TST;BLEU;BERT_F1;REF_CUMLE;TST_CUMLE\\n\")  # Başlık satırı\n",
    "\n",
    "    for (referans_grup, referans_metni), (test_grup, test_metni) in zip(referans_metinleri, test_metinleri):\n",
    "        # SOV puanı hesapla\n",
    "        result1 = bul_puanSOV(referans_metni)\n",
    "        result2 = bul_puanSOV(test_metni)\n",
    "\n",
    "        # BLEU puanı hesapla\n",
    "        result = bul_puanBLEU(referans_metni, test_metni)\n",
    "        bleu_skor = result\n",
    "\n",
    "        # BERT puanı hesapla\n",
    "        bert_skor = bul_puanBERT([referans_metni], [test_metni])\n",
    "        _, _, f1_skor = bert_skor  # F1 skorunu al\n",
    "\n",
    "        # Çıktıyı dosyaya yaz\n",
    "        file.write(f\"{referans_grup};{result1['Puan']};{result1['word_order']};{result2['Puan']};{result2['word_order']};{bleu_skor};{f1_skor.mean():.4f};{referans_metni};{test_metni}\\n\")\n",
    "\n",
    "print(f\"✅ {output_dosyasi} başarıyla oluşturuldu ve tüm puanlar kaydedildi!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
